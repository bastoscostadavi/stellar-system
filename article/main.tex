\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}

\title{Gravitational Painting: \\ N-Body Simulations in Dimensionless Units}
\author{}
\date{}

\begin{document}

\maketitle

\section{Introduction}

We present a systematic approach to generating training data for neural networks that learn gravitational N-body dynamics. Our method produces paired images: initial conditions (point configurations) and their temporal evolution (trajectory paintings), enabling machine learning models to predict dynamical outcomes from static initial states.

\section{Dimensionless Units and Scaling Symmetry}

\subsection{Newtonian Gravity Scaling}

The equations of motion for N-body gravitational systems are:
\begin{equation}
\ddot{\mathbf{r}}_i = -G \sum_{j \neq i} \frac{m_j (\mathbf{r}_i - \mathbf{r}_j)}{|\mathbf{r}_i - \mathbf{r}_j|^3}
\end{equation}

These equations exhibit a scaling symmetry under the transformation:
\begin{equation}
m \to \lambda_m m, \quad \mathbf{r} \to \lambda_r \mathbf{r}, \quad t \to \lambda_t t
\end{equation}
provided the constraint
\begin{equation}
\frac{\lambda_m}{\lambda_r^3} = \lambda_t^{-2}
\end{equation}
is satisfied. This implies that the dimensionless quantity $G m t^2 / r^3$ is invariant under rescaling.

\subsection{Choice of Units}

This scaling symmetry allows us to fix any two of the three scales (mass, length, time), with the third determined by the constraint. We adopt the standard convention in N-body simulations:

\begin{itemize}
\item \textbf{Gravitational constant}: $G = 1$
\item \textbf{Total mass}: $M = \sum_{i=1}^N m_i = 1$
\item \textbf{Length scale}: Characteristic radius $\sim 1$
\end{itemize}

Time is then measured in dynamical units:
\begin{equation}
t_{\text{dyn}} \sim \sqrt{\frac{r^3}{GM}}
\end{equation}

\textbf{Benefits}:
\begin{itemize}
\item All simulations are directly comparable in the same units
\item No arbitrary physical scales (kg, meters, seconds)
\item Physics is universal and scale-invariant
\item Optimal for neural network training (normalized inputs/outputs)
\end{itemize}

\section{Initial Conditions}

\subsection{Mass Distribution}

Individual masses are drawn from a uniform distribution:
\begin{equation}
m_i \sim \mathcal{U}(0, 1)
\end{equation}
Masses are then normalized:
\begin{equation}
m_i \gets \frac{m_i}{\sum_{j=1}^N m_j}
\end{equation}
ensuring $\sum m_i = 1$.

\textbf{Rationale}: Uniform distribution provides a simple baseline where all mass scales are equally likely. This creates systems with similar-sized bodies, suitable for studying collective dynamics without hierarchical structure.

\subsection{Position Distribution}

Positions are uniformly distributed in a disk of unit radius:
\begin{align}
\theta_i &\sim \mathcal{U}(0, 2\pi) \\
r_i &\sim \sqrt{\mathcal{U}(0, 1)} \\
\mathbf{r}_i &= r_i (\cos\theta_i, \sin\theta_i)
\end{align}

The $\sqrt{r}$ scaling ensures uniform density in the disk (area element $\propto r \, dr$).

\subsection{Velocity Distribution}

All bodies start with \textbf{zero initial velocity}:
\begin{equation}
\mathbf{v}_i(t=0) = \mathbf{0}, \quad \forall i
\end{equation}

\textbf{Rationale}: This represents a ``cold start'' or gravitational collapse scenario, where the system begins from rest and evolves purely under mutual gravitational attraction. This choice:
\begin{itemize}
\item Simplifies the initial state (positions and masses only)
\item Produces interesting, non-trivial dynamics (collapse, close encounters, ejections)
\item Reduces the input space for the neural network
\end{itemize}

\section{Numerical Integration}

We use the 4th-order Runge-Kutta (RK4) method to integrate the equations of motion:
\begin{equation}
\mathbf{r}_i(t + \Delta t), \, \mathbf{v}_i(t + \Delta t) = \text{RK4}(\mathbf{r}_i(t), \mathbf{v}_i(t), \Delta t)
\end{equation}

\textbf{Parameters}:
\begin{itemize}
\item Simulation time: $T = 50$ (dynamical units, default)
\item Number of steps: $N_{\text{steps}} = 10{,}000$ (default)
\item Time step: $\Delta t = T / N_{\text{steps}} = 0.005$
\end{itemize}

The RK4 method provides a good balance between accuracy ($\mathcal{O}(\Delta t^4)$ per step) and computational efficiency.

\section{Visualization}

\subsection{Initial Points Image}

Bodies are rendered as Gaussian spots with radii linearly proportional to mass:
\begin{equation}
r_{\text{line}, i} = 1 + 2Nm_i \quad \text{(pixels)}
\end{equation}
\begin{equation}
r_{\text{dot}, i} = 1.3 \times r_{\text{line}, i} \quad \text{(pixels)}
\end{equation}
where $N$ is the number of bodies. The factor $2N$ ensures that line thickness scales with the system size, and dots are 30\% larger than trajectory lines for visibility.

\textbf{Coordinate frame}: Centered at the center of mass, with extent $\pm 1.25 \times r_{\max}$ where $r_{\max} = \max_i |\mathbf{r}_i - \mathbf{r}_{\text{COM}}|$.

\subsection{Trajectory Painting}

\subsubsection{Spatial Resampling}

To ensure brightness is proportional to velocity (not timestep density), trajectories are resampled with uniform spatial spacing:

\begin{enumerate}
\item \textbf{Arc length parameterization}: For each body's trajectory $\mathbf{r}_i(t)$, compute cumulative arc length:
\begin{equation}
s_k = \sum_{j=0}^{k-1} |\mathbf{r}_{i,j+1} - \mathbf{r}_{i,j}|
\end{equation}

\item \textbf{Uniform spatial sampling}: Resample at uniform intervals $\Delta s = 0.001$ (world units):
\begin{equation}
s_{\text{sample}} = 0, \Delta s, 2\Delta s, \ldots, s_{\text{total}}
\end{equation}

\item \textbf{Interpolation}: Linearly interpolate positions $\mathbf{r}(s)$ and velocities $\mathbf{v}(s)$ at each sample point.
\end{enumerate}

\textbf{Rationale}: Fast segments naturally have more sample points (long path length), slow segments have fewer. Brightness becomes proportional to velocity magnitude, independent of timestep density.

\subsubsection{Rendering}

\textbf{Line width}: Same as initial points:
\begin{equation}
r_{\text{line}, i} = 1 + 2Nm_i \quad \text{(pixels)}
\end{equation}

\textbf{Intensity}: Sigmoid mapping of velocity magnitude:
\begin{equation}
I(v) = \frac{1}{1 + e^{-v}}
\end{equation}
where $v$ is velocity in dimensionless units. Range: $[0.5, 1.0]$ for $v \in [0, \infty)$.

\textbf{Blending}:
\begin{itemize}
\item \textit{Within trajectory}: Maximum (no accumulation) $\to$ clean, velocity-based intensity
\item \textit{Between trajectories}: Additive, capped at 1.0 $\to$ natural brightening at crossings
\end{itemize}

\textbf{Gaussian rendering}: Each sample point rendered as:
\begin{equation}
w(\mathbf{x}) = I(v) \cdot \exp\left(-\frac{|\mathbf{x} - \mathbf{r}|^2}{2r_{\text{line}}^2}\right)
\end{equation}

\textbf{Final positions}: Overlaid as white dots ($r_{\text{final}} = 1.2 \times r_{\text{line}}$) with black outlines for contrast.

\section{Data Generation for Neural Networks}

\subsection{Dataset Structure}

Each sample consists of a paired image set:
\begin{itemize}
\item \textbf{Input}: Initial points image (positions + masses)
\item \textbf{Output}: Trajectory painting (evolved dynamics)
\end{itemize}

Files are named: \texttt{prefix\_n\{N\}\_seed\{S\}\_\{points|painting\}.png}

\subsection{Recommended Dataset Sizes}

\begin{itemize}
\item \textbf{Proof of concept}: 500--1,000 examples per $N$
\item \textbf{Production training}: 5,000--10,000 examples per $N$
\item \textbf{Large-scale}: 20,000--50,000 examples for $N \geq 10$
\end{itemize}

\textbf{Note}: Train separate models for each $N$ or include $N$ as an input feature, since complexity scales as $\mathcal{O}(N^2)$.

\subsection{Data Augmentation}

The physics is rotationally invariant, enabling augmentation:
\begin{itemize}
\item Random rotations by $\theta \in [0, 2\pi)$
\item Horizontal/vertical flips
\item Effectively multiplies dataset size by $\sim 8$
\end{itemize}

\section{Neural Network Architecture Considerations}

\textbf{Input}: $2048 \times 2048$ grayscale image (initial points)

\textbf{Output}: $2048 \times 2048$ grayscale image (trajectory painting)

\textbf{Recommended architectures}:
\begin{itemize}
\item U-Net: Standard for image-to-image translation
\item Conditional GAN (pix2pix): For realistic texture generation
\item Physics-informed neural networks: Incorporate gravitational constraints
\end{itemize}

\textbf{Loss functions}:
\begin{itemize}
\item L1 or L2 pixel-wise loss
\item Perceptual loss (VGG features)
\item Adversarial loss (if using GAN)
\end{itemize}

\section{Computational Details}

\textbf{Image resolution}: $2048 \times 2048$ pixels (grayscale, 8-bit)

\textbf{Rendering optimization}: Local bounding boxes around each trajectory point (3$\sigma$ cutoff) reduce computation from $\mathcal{O}(N \cdot N_{\text{steps}} \cdot W \cdot H)$ to $\mathcal{O}(N \cdot N_{\text{steps}} \cdot r^2)$ where $r \ll \min(W, H)$.

\textbf{Typical generation time}: $\sim$20--60 seconds per sample (depending on $N$ and $N_{\text{steps}}$).

\section{Summary}

Our simulation framework leverages the scale-invariance of Newtonian gravity to produce a universal, dimensionless dataset of N-body dynamics. Key design choices:

\begin{enumerate}
\item Dimensionless units ($G=1$, $M=1$) ensure scale-invariance
\item Zero initial velocities simplify input and produce interesting collapse dynamics
\item Uniform mass distribution creates systems with similar-sized bodies
\item Spatial resampling ensures brightness $\propto$ velocity (not timestep density)
\item Linear mass-to-radius mapping: $r = 1 + 2Nm$ (pixels)
\item Sigmoid velocity-to-intensity mapping: $I = 1/(1 + e^{-v})$
\item Hybrid blending: maximum within trajectories, additive between trajectories
\item High-resolution rendering ($2048^2$) preserves fine trajectory details
\item Separated workflow: simulation generation and visualization are independent
\end{enumerate}

This approach produces clean, physically accurate visualizations where trajectory brightness directly reflects velocity magnitude, enabling effective training of neural networks to learn gravitational dynamics.

\end{document}
